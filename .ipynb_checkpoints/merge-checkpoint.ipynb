{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76863be7-63f7-4447-8527-135871875e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7f2d894-f241-431c-9009-bd60f8b1067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "ratings = np.genfromtxt('ratings.csv', delimiter=',')[1:]\n",
    "ratings[:,2] = ratings[:,2]*2 #met le rating sur 10\n",
    "ratings = ratings.astype(int)\n",
    "\n",
    "movies = pd.read_csv('movies.csv', header=None).values[1:]\n",
    "movies[:,0] = movies[:,0].astype(int)\n",
    "for idx, genres in enumerate(movies[:,2]):\n",
    "    movies[idx][2] = genres.split('|')\n",
    "    \n",
    "#creates dictionnary that links idx to movies ids\n",
    "movie_idx_from_id = {}\n",
    "for i in range(movies.shape[0]):\n",
    "    movie_idx_from_id[movies[i,0]] = i\n",
    "    \n",
    "#retrieves all existing genres    \n",
    "genres = set() \n",
    "for gs in movies[:,2]:\n",
    "    for g in gs:\n",
    "        genres.add(g)\n",
    "\n",
    "#creates dictionnary that links ids with genres string\n",
    "id_from_genre = {}\n",
    "for idx, genre in enumerate(genres):\n",
    "    id_from_genre[genre] = idx\n",
    "    \n",
    "links = np.genfromtxt('links.csv', delimiter=',')[1:].astype(int)\n",
    "\n",
    "tags = pd.read_csv('tags.csv', header=None).values[1:]\n",
    "tags[:,0:2] = tags[:,0:2].astype(int)\n",
    "tags[:,3] = tags[:,3].astype(int)\n",
    "\n",
    "#creates a dictionnary that links a user id and a movie to a rating\n",
    "rating_dict = {}\n",
    "for r in ratings:\n",
    "    rating_dict[(r[0],r[1])] = r[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b97affa-9271-4fbd-bbbe-c54555305ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#content-based method\n",
    "def get_sets(ratings, ratio):\n",
    "    temp = ratings[ratings[:,0] == 1]\n",
    "    step = int(np.round(temp.shape[0]*ratio))\n",
    "\n",
    "    train_ratings = temp[:step]\n",
    "    test_ratings = temp[step:]\n",
    "\n",
    "    users = set(ratings[:,0])\n",
    "    users.remove(1)\n",
    "\n",
    "    for i in set(users): #for all users expect the first\n",
    "        temp = ratings[ratings[:,0] == i]\n",
    "        step = int(np.round(temp.shape[0]*ratio))\n",
    "\n",
    "        train_ratings = np.concatenate((train_ratings, temp[:step]))\n",
    "        test_ratings = np.concatenate((test_ratings, temp[step:]))\n",
    "        \n",
    "    print(f\"Training set shape: {train_ratings.shape[0]}\\nTest set shape: {test_ratings.shape[0]}\\n\")\n",
    "    return train_ratings, test_ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5678b7fc-d4db-44cd-b32c-48f29847e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profils(ratings):\n",
    "    #computing TF matrix\n",
    "    TF = np.zeros((len(genres), movies.shape[0]))\n",
    "    for idx, gs in enumerate(movies[:,2]):\n",
    "        for g in gs:\n",
    "            TF[id_from_genre[g],idx] = 1\n",
    "            \n",
    "    #computing the inverse frequency\n",
    "    occurences = np.zeros(TF.shape[0])\n",
    "    for g in genres:\n",
    "        occurences[id_from_genre[g]] = int(np.sum(TF[:][id_from_genre[g]]))\n",
    "    IDF = np.log(TF.shape[1]/occurences)\n",
    "    \n",
    "    #computing the TD-IDF score for every pair of feature-item\n",
    "    TF_IDF = IDF*TF.T\n",
    "    \n",
    "    nb_ids = len(set(ratings[:,0])) #610 ids with at least 1 rating from each\n",
    "    like_threshold = 8\n",
    "    liked_films = [[] for _ in range(nb_ids)] #real id is +1 because array starts with 0\n",
    "    given_scores = [[] for _ in range(nb_ids)] \n",
    "    for rating in ratings:\n",
    "        if(rating[2] >= like_threshold):\n",
    "            liked_films[rating[0]-1].append(movie_idx_from_id[rating[1]])\n",
    "            given_scores[rating[0]-1].append(rating[2])\n",
    "            \n",
    "    #computing the user profils\n",
    "    user_profils = np.zeros((nb_ids,len(genres)))\n",
    "    for i in range(nb_ids):\n",
    "        profil = np.zeros(len(genres))\n",
    "        for j in range(len(liked_films[i])): #using the weighted average aggregation method\n",
    "            profil += given_scores[i][j]*TF_IDF[liked_films[i][j]] #sum the profils of liked movies with the weight given by the user rating score\n",
    "        profil /= max(np.sum(given_scores[i]),1) #avoid division by 0 when user has no liked movie\n",
    "        user_profils[i] =profil\n",
    "        \n",
    "    return user_profils, TF_IDF, liked_films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2aa311-927d-4c4e-9ca2-918545fef245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collaborative filtering\n",
    "#find similar users\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "  if len(doc1)==0 or len(doc2)==0:\n",
    "    return 0.0\n",
    "  else:\n",
    "    inter = doc1.intersection(doc2)\n",
    "    union = doc1.union(doc2)\n",
    "    return float(len(inter))/float(len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d9291c6-3381-42d9-955c-fdd7f346a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(user_id_1,user_id_2):\n",
    "    return np.dot(user_id_1,user_id_2)/(norm(user_id_1)*norm(user_id_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c93ffb9-f53f-4833-aa72-05d46a6295d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction ratings\n",
    "def average_prediction(user,movie,similar_users): #user: user_id    movie:movie_id    similar_users: list of users_id    \n",
    "    prediction = 0\n",
    "    count = 0  \n",
    "    for y in similar_users:  \n",
    "        r = rating_dict.get((y,movie),-1)\n",
    "        if(r != -1):\n",
    "            prediction += r\n",
    "            count += 1\n",
    "    \n",
    "    if(count < 3):  #We want at least 3 ratings to make a prediction \n",
    "        return -1 \n",
    "    return prediction/count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a7ddc91-f6f0-469f-b650-02abedfd5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_array(user_id):\n",
    "    res = []\n",
    "    for m in movies[:,0]:\n",
    "        res.append(rating_dict.get((user_id,m),0))\n",
    "    return res\n",
    "\n",
    "#get the k most similar users to user_id based on cosine similarity\n",
    "def get_similar_users(ratings, user_id,k):\n",
    "    user_id_ratings = get_rating_array(user_id)\n",
    "    cos = []\n",
    "    for uid in range(1,len(set(ratings[:,0]))): #number of users\n",
    "        uid_ratings = get_rating_array(uid)\n",
    "        cos.append(cosine_similarity(user_id_ratings,uid_ratings))\n",
    "    \n",
    "    return [cos.index(i) for i in sorted(cos,reverse=True)][1:k+1] #we don't use the first result because it's the user_id itself        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52bd5056-46e4-446b-a02c-6675960ff4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users_jaccard(ratings, user_id,k):\n",
    "    user_id_ratings = set(ratings[np.where((ratings[:,0] == user_id)),1].tolist()[0])\n",
    "    jac = []\n",
    "    for uid in range(1,len(set(ratings[:,0]))): #number of users\n",
    "        uid_ratings = set(ratings[np.where((ratings[:,0] == uid)),1].tolist()[0])\n",
    "        jac.append(jaccard_similarity(user_id_ratings,uid_ratings))\n",
    "    \n",
    "    return [jac.index(i) for i in sorted(jac,reverse=True)][1:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d227625-454c-4289-b31e-ad6cac20f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_movies_predictions(user_id,similar_users,k): #k: nb of recommendations        \n",
    "    rat = [average_prediction(user_id,m,similar_users) for m in movies[:,0]]   \n",
    "    return (-np.array(rat)).argsort()[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b4b0883-3ee1-49ab-a0c3-88714eefa88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user-user collaborative filtering\n",
    "def recommendation_CF(ratings, user_id,k,nb_similar,similarity_method): #k: nb of recommendations\n",
    "    if(similarity_method == \"jaccard\"):    \n",
    "        similar = get_similar_users_jaccard(ratings, user_id,nb_similar)\n",
    "    else:\n",
    "        similar = get_similar_users(ratings, user_id,nb_similar)\n",
    "    prediction = get_best_movies_predictions(user_id,similar,k)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9869c98a-78d0-40d0-8c8b-fa0fe4be7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_CB(ratings, user_id, nb_reco):\n",
    "    \n",
    "    #content based predictions\n",
    "    \n",
    "    user_profils, TF_IDF, liked_films = get_profils(ratings)\n",
    "        \n",
    "    #cosine similarity avoiding usage of for loop\n",
    "    top = user_profils@TF_IDF.T #scalar products\n",
    "    bottom = (np.linalg.norm(user_profils, axis = 1).reshape((user_profils.shape[0],1))@np.linalg.norm(TF_IDF, axis = 1).reshape((1,TF_IDF.shape[0]))) #mul of norms\n",
    "    bottom[bottom == 0] = 1 #avoids div by 0\n",
    "    scores = top/bottom\n",
    "    \n",
    "    \n",
    "    scores_not_watched = scores[user_id].copy()\n",
    "    scores_not_watched[liked_films[user_id]] = 0 #removes already noted movies\n",
    "    return np.argpartition(scores_not_watched, nb_reco*-1)[nb_reco*-1:] #gets the k unwatched movies with the highest predicted score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "741988fd-1589-4025-9d03-b060fc715e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(ratings, user_id,k,nb_similar,similarity_method):\n",
    "    pred_CB = recommendation_CB(ratings, user_id-1, k)\n",
    "    pred_CF = recommendation_CF(ratings, user_id,k,nb_similar,similarity_method)\n",
    "    pred = []\n",
    "    idx = 0\n",
    "    while(len(pred) != k):\n",
    "        if(idx%2 == 0):\n",
    "            if(pred_CB[int(np.floor(idx/2))] not in pred):\n",
    "                pred.append(pred_CB[int(np.floor(idx/2))])\n",
    "                idx+=1\n",
    "        else:\n",
    "            if(pred_CF[int(np.floor(idx/2))] not in pred):\n",
    "                pred.append(pred_CF[int(np.floor(idx/2))])\n",
    "                idx+=1\n",
    "    for l in pred:\n",
    "        print(f\"id:{l}{(4-int(np.log10(l)))*' '} movieId:{movies[l,0]}{(6-int(np.log10(movies[l,0])))*' '} Title:{movies[l,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa9487b5-dea1-4392-82a4-e3ca60133fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:9394  movieId:164226  Title:Maximum Ride (2016)\n",
      "id:2765  movieId:3703    Title:Road Warrior, The (Mad Max 2) (1981)\n",
      "id:7374  movieId:79139   Title:Sorcerer's Apprentice, The (2010)\n",
      "id:2290  movieId:3037    Title:Little Big Man (1970)\n",
      "id:6448  movieId:51939   Title:TMNT (Teenage Mutant Ninja Turtles) (2007)\n",
      "id:971   movieId:1272    Title:Patton (1970)\n",
      "id:8357  movieId:108932  Title:The Lego Movie (2014)\n",
      "id:2016  movieId:2687    Title:Tarzan (1999)\n",
      "id:5490  movieId:26340   Title:Twelve Tasks of Asterix, The (Les douze travaux d'Astérix) (1976)\n",
      "id:2582  movieId:3451    Title:Guess Who's Coming to Dinner (1967)\n"
     ]
    }
   ],
   "source": [
    "user = 1\n",
    "k = 10\n",
    "\n",
    "recommendation(ratings, user,k,100,\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea7e0c0f-65ef-4117-871a-a3dc5d574194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ratings, ratio):\n",
    "    train_ratings, test_ratings = get_sets(ratings, ratio)\n",
    "    user_profils, TF_IDF, lf = get_profils(train_ratings)\n",
    "    \n",
    "    l = np.max(train_ratings[:,0])\n",
    "    tot = 0\n",
    "    bot = 0\n",
    "    for i in range(l):\n",
    "        test_ids_of_user = [movie_idx_from_id[j] for j in test_ratings[test_ratings[:,0] == i+1][:,1]] #gets the ids of the test film of the user\n",
    "        \n",
    "        top = user_profils[i]@TF_IDF[test_ids_of_user,:].T\n",
    "        bottom = np.linalg.norm(user_profils[i])*np.linalg.norm(TF_IDF[test_ids_of_user,:], axis = 1) #mul of norms\n",
    "        bottom[bottom == 0] = 1 #avoids div by 0\n",
    "        scores = top/bottom #computes the scores for each film\n",
    "        rank = np.argsort(scores) #gets the ranks of films (1st arg is the worst score and last is the bets)\n",
    "        \n",
    "        similar = get_similar_users(train_ratings, i+1,100) #gets similar users\n",
    "        pred_CF = get_best_movies_predictions(i+1,similar,-1) #movies ranked\n",
    "        pred_CF = [p for p in pred_CF if p in test_ids_of_user] #keeps movies that are in the test set \n",
    "        pred_CF = np.array([test_ids_of_user.index(p) for p in pred_CF]) #gets the ids in test_ids_of_user while keeping the rank\n",
    "        \n",
    "        if(rank.size == pred_CF.size): #bug solution\n",
    "            v = []\n",
    "            for j in range(len(test_ids_of_user)):\n",
    "                v.append(np.where(rank == j)[0][0] + np.where(pred_CF == j)[0][0]) #gets the sum of ranks\n",
    "            pred = np.argsort(v) #gets the final rank of every movie\n",
    "\n",
    "            ra = np.array([test_ratings[test_ratings[:,0] == i+1][:,2][j] for j in pred]) #gets the ratings of the films with the permutation given in rank\n",
    "            nb_disliked = np.sum(ra < 8)\n",
    "            ra = ra[nb_disliked:]#we dismiss the nb_disliked films which have the worst score for our evaluation\n",
    "            if(ra.size != 0): #we only consider cases with more than 1 recommendation\n",
    "                tot += np.sum(ra >= 8)/np.max([ra.size,1]) #computes the ratio of films recommended that have a rating higher than 8\n",
    "                bot += 1\n",
    "    print(f\"Average rate of prediction accuracy: {tot/bot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d612a29-bbb8-4e25-99c7-a82e8dde58f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: 80672\n",
      "Test set shape: 20164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clement\\AppData\\Local\\Temp\\ipykernel_4244\\204242320.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.dot(user_id_1,user_id_2)/(norm(user_id_1)*norm(user_id_2))\n"
     ]
    }
   ],
   "source": [
    "evaluate(ratings, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee70443-f18e-47fb-9be8-8ca82f20f72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
